# NEXUS: Evidence-Grounded AI Interview System (v3.0)

> **Research Edition:** High-Performance, Asynchronous, Type-Safe.

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-009688.svg)](https://fastapi.tiangolo.com)
[![Asyncio](https://img.shields.io/badge/Asyncio-Powered-success.svg)](https://docs.python.org/3/library/asyncio.html)
[![Pydantic](https://img.shields.io/badge/Pydantic-v2-e92063.svg)](https://docs.pydantic.dev/)

NEXUS is an automated competency assessment system designed for high-throughput, reproducible research. It conducts voice-based interviews, analyzing candidates in real-time using a novel **Gap-Driven Assessment Pipeline**.

---

## üöÄ Key Innovations

### 1. Asynchronous Event-Driven Architecture
Unlike traditional synchronous Python scripts, NEXUS v3.0 is built on `asyncio` and `FastAPI`.
- **Non-blocking I/O:** Audio transcription (STT) and text synthesis (TTS) occur without halting the server.
- **Parallel Analysis:** CV and Job Description parsing happens concurrently (`asyncio.gather`), reducing setup latency by ~40%.
- **High Concurrency:** Handles multiple simultaneous interview sessions via a stateless REST API design with in-memory session management.

### 2. Evidence-Grounded Scoring
The system implements a rigorous "Chain-of-Thought" scoring mechanism.
- **Traceability:** Every score (0-5) must be backed by a *direct quotation* from the transcript.
- **Type Safety:** All LLM outputs are validated against strict **Pydantic** models (`nexus_core/structs.py`), ensuring 100% schema compliance.
- **Deterministic Evaluation:** Uses low-temperature sampling for scoring to maximize reproducibility.

### 3. Resilience & Reliability
- **Smart Key Rotation:** The `AsyncLLMGateway` automatically rotates through multiple Groq API keys to bypass rate limits.
- **Exponential Backoff:** Built-in retry logic (via `tenacity`) handles transient API failures gracefully.
- **Model Fallback Cascade:** Automatically degrades from `Llama-3.3-70b` to `Qwen-32b` or `Llama-8b` if the primary model is unavailable.

---

## üèóÔ∏è System Architecture

The system follows a strict layered architecture to separate concerns:

```mermaid
graph TD
    Client[Web UI (v2)] <-->|REST / WebSocket| Server[FastAPI Server]

    subgraph "NEXUS Core"
        Server <--> Orchestrator[Interview Orchestrator]
        Orchestrator <--> SessionMgr[Session Manager]
        Orchestrator <--> LLM[Async LLM Gateway]
    end

    subgraph "Data Layer (Pydantic)"
        SessionMgr --> Session[Session State]
        Session --> CV[CV Analysis]
        Session --> JD[JD Analysis]
        Session --> Scores[Evidence Scores]
        Session --> EyeMetrics[Eye Contact Logs]
    end

    subgraph "External Services"
        LLM <-->|Async HTTP| Groq[Groq Cloud API]
        Server <-->|Edge-TTS| TTS[Speech Synthesis]
    end
```

### Core Components

| Component | File | Responsibility |
|-----------|------|----------------|
| **Server** | `nexus_server_v2.py` | Async API endpoints, static file serving, request validation. |
| **Orchestrator** | `nexus_core/orchestrator.py` | The "Brain". Manages interview flow, parallelism, and state transitions. |
| **Gateway** | `nexus_core/llm_gateway.py` | Handles Groq API connections, retries, and key rotation. |
| **Structs** | `nexus_core/structs.py` | Pydantic definitions for all data objects (CV, JD, Questions, Scores). |
| **UI** | `nexus_ui_v2.html` | Modern, responsive frontend with real-time audio and video support. |

---

## ‚öñÔ∏è Ethics & Privacy (Camera Usage)

This system includes an **Eye Contact Tracking** feature designed for research purposes (measuring non-verbal engagement) and academic integrity (anti-cheating).

**Justification:**
1.  **Engagement Metrics:** Eye contact is a key indicator of confidence and engagement in human interviews. By tracking gaze direction, the system attempts to simulate this human perception.
2.  **Academic Integrity:** To ensure the candidate is the one answering questions without reading from a script or using external aids, the camera validates presence and focus.

**Privacy Safeguards:**
*   **Local Processing:** The video stream is processed entirely on the client-side (or securely transmitted for metadata extraction only).
*   **No Video Storage:** NEXUS **does not record or store raw video footage**. Only lightweight metadata (timestamp, gaze_confidence) is logged in the session JSON.
*   **Consent:** Candidates must explicitly opt-in via the "Enable Eye Contact Tracking" checkbox before the camera activates.

---

## ‚ö° Quick Start

### Prerequisites
- Python 3.10 or higher
- A Groq API Key (or multiple for rotation)

### Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/your-repo/nexus.git
    cd nexus
    ```

2.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Configure Environment:**
    Create a `.env` file in the root directory:
    ```env
    GROQ_API_KEY=gsk_...
    # Optional: Add more keys for higher throughput
    GROQ_API_KEY_2=gsk_...
    GROQ_API_KEY_3=gsk_...
    ```

### Running the System

Start the high-performance server (v3.0):

```bash
python nexus_server_v2.py
```

Open your browser to: **http://localhost:8000**

---

## üß™ Research Workflow

1.  **Setup Phase:**
    - Paste the Candidate CV and Target Job Description.
    - Click **"Analyze"**. The system performs parallel extraction and Gap Analysis.
    - Review identified gaps (Missing Skills, Probe Areas) in the sidebar.

2.  **Interview Phase:**
    - Enable Camera (Optional) and click **"Start Interview"**.
    - Use the **Spacebar** to record your answers.
    - The system will ask adaptive questions based on your responses and the gap analysis.
    - Real-time scoring updates will appear in the top-right corner.

3.  **Analysis Phase:**
    - Upon completion, a structured **JSON Report** is generated.
    - The report includes detailed evidence chains, dimension scores, eye contact metrics, and a hiring recommendation.

---

*Built for the Future of Automated Assessment.*
